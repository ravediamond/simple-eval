{
  "title": "EvalNow - AI Response Evaluation",
  "subtitle": "AI Response Evaluation Report",
  "hero_title": "Know if your AI chatbot works — in minutes.",
  "hero_subtitle": "Upload your conversations. Get a score, plain-English feedback, and a shareable report. No technical setup, no code.",
  "upload_button": "Upload & Evaluate Free",
  "new_evaluation": "New Evaluation",
  "evaluation_results": "Evaluation Results",
  "privacy_notice": "Your data stays private and is automatically deleted after evaluation",
  "try_free_title": "Try it free — upload your chatbot's answers today",
  "upload_instruction": "Upload a CSV, Excel, or JSONL file with three columns:",
  "column_question": "question",
  "column_reference": "reference",
  "column_answer": "answer",
  "column_question_description": "what users ask",
  "column_reference_description": "the correct answer",
  "column_answer_description": "what your chatbot replied",
  "usage_limits_title": "Current Usage Limits",
  "limit_questions": "50 questions maximum per file",
  "limit_evaluations": "3 evaluations per day per user",
  "higher_limits": "Need higher limits? Join our waiting list for higher limits and priority features",
  "drag_drop": "Drag & drop your file here",
  "or_click": "or click to browse",
  "choose_file": "Choose File",
  "join_waiting_list": "Join Waiting List",
  "and": "and",
  "supported_formats": "Supported formats: CSV, JSONL, Excel (.xlsx, .xls)",
  "executive_summary": "Executive Summary",
  "key_insights": "Key Insights",
  "recommendations": "Recommendations",
  "detailed_results": "Detailed Results",
  "score_distribution": "Score Distribution",
  "ai_powered_analysis": "AI-Powered Analysis",
  "metric": "Metric",
  "value": "Value",
  "assessment": "Assessment",
  "average_score": "Average Score",
  "pass_rate": "Pass Rate (≥70%)",
  "total_questions": "Total Questions",
  "good": "Good",
  "excellent": "Excellent",
  "needs_improvement": "Needs Improvement",
  "poor": "Poor",
  "comprehensive_sample": "Comprehensive Sample",
  "limited_sample": "Limited Sample",
  "file": "File",
  "generated": "Generated",
  "report_type": "Report Type",
  "comprehensive_analysis": "Comprehensive AI Evaluation Analysis",
  "question": "Question",
  "score": "Score",
  "currently_in_beta": "Currently in Beta",
  "beta_description": "Free access with 50 questions/file and 3 evaluations/day. Join our waiting list for higher limits, priority support, and enterprise features.",
  "expected_file_format": "Expected File Format:",
  "file_format_description": "Your file should have these three columns:",
  "example_question": "What is 2+2?",
  "example_reference": "Four",
  "example_answer": "2+2 equals 4",
  "example_question_2": "Capital of France?",
  "example_reference_2": "Paris",
  "example_answer_2": "The capital city of France is Paris",
  "main_problem": "Your chatbot talks a lot. But is it actually helping?",
  "problem_description": "Hard to judge by scrolling through transcripts",
  "solution_title": "EvalNow makes chatbot evaluation simple:",
  "ai_review_description": "Our AI reviews every response like a smart, unbiased critic.",
  "perfect_for": "Perfect for:",
  "target_product_managers": "Product Managers who need clear metrics to assess chatbot performance",
  "target_team_leads": "Team Leads who require shareable reports for stakeholder meetings",
  "target_founders": "Founders who want measurable progress to show investors/clients",
  "how_it_works": "How it works",
  "step_1": "Upload your chatbot's conversations",
  "step_1_description": "CSV, JSONL, or Excel files with question-reference-answer format",
  "step_2": "AI analyzes every response",
  "step_2_description": "Our AI judge compares answers against references and provides reasoning",
  "step_3": "Get actionable insights",
  "step_3_description": "Clear scores, plain-English feedback, and shareable PDF reports",
  "problem_subtitle": "Getting clear answers about your chatbot's performance shouldn't be this hard",
  "problem_1_title": "Hard to judge by scrolling through transcripts",
  "problem_1_description": "Reading through hundreds of conversations manually is time-consuming and you miss patterns that matter.",
  "problem_2_title": "Technical eval tools are overwhelming",
  "problem_2_description": "Complex dashboards and metrics that require a data science degree to understand. You need clarity, not confusion.",
  "problem_3_title": "No clear business impact",
  "problem_3_description": "Even if you find issues, it's unclear which improvements would actually help your business goals.",
  "solution_step_1": "Upload your conversations in a file (CSV, Excel, JSON).",
  "solution_step_2": "Our AI analyzes every response against your ideal answers.",
  "solution_step_3": "Get clear scores and actionable feedback in plain English.",
  "you_get": "You get:",
  "result_overall_score": "An overall score",
  "result_explanation": "A clear explanation of strengths and weaknesses",
  "result_advice": "Practical advice on what to improve",
  "result_pdf_report": "A polished PDF report to share with your team",
  "results_look_like": "Here's what your results look like:",
  "evaluation_in_progress": "Evaluation in Progress",
  "please_wait": "Please wait while we evaluate your AI responses using advanced language models. This may take a few moments depending on the number of questions.",
  "file_label": "File:",
  "status_label": "Status:",
  "status_running": "Running AI evaluation...",
  "step_uploaded": "File uploaded and validated",
  "step_evaluation": "AI evaluation in progress",
  "answer": "Answer",
  "ai_analysis_summary": "AI Analysis & Summary",
  "help_us_improve": "Help Us Improve",
  "feedback_description": "Your feedback helps us make EvalNow better. How was your experience?",
  "satisfaction_question": "How satisfied are you with the results?",
  "would_recommend": "Would you recommend EvalNow?",
  "quick_statistics": "Quick Statistics",
  "pass_rate": "Pass Rate",
  "about_evaluation": "About This Evaluation",
  "no_data_stored": "No data stored",
  "ai_powered_scoring": "AI-powered scoring",
  "real_time_evaluation": "Real-time evaluation",
  "detailed_feedback": "Detailed feedback",
  "download_pdf_report": "Download PDF Report",
  "additional_comments": "Additional comments (optional):",
  "submit_feedback": "Submit Feedback",
  "correct_answer": "Correct Answer",
  "incorrect_answer": "Incorrect Answer",
  "dataset_guide_title": "How to Build Your Test Dataset",
  "dataset_guide_subtitle": "Create effective evaluation data in 3 simple steps",
  "dataset_step1_title": "Questions your chatbot should answer well",
  "dataset_step1_description": "Add 10-20 questions that represent your chatbot's main purpose. These should be typical user questions.",
  "dataset_step2_title": "Cover all important topics",
  "dataset_step2_description": "Include questions from different areas: basic info, complex scenarios, edge cases your users might ask.",
  "dataset_step3_title": "Questions it should NOT answer",
  "dataset_step3_description": "Test inappropriate requests, off-topic questions, or queries that should be redirected to human support.",
  "dataset_tip": "<strong>Tip:</strong> Mix easy and challenging questions to get a complete picture of your chatbot's performance",
  "perfect_for": "Perfect for:",
  "problem_3_title": "Stakeholders want clear answers, not data dumps",
  "problem_3_description": "Your boss wants to know: \"Is it working?\" Your report needs to be simple, clear, and shareable.",
  "perfect_for_product_managers": "Product managers",
  "perfect_for_product_managers_desc": "Know if your bot is meeting the mark",
  "perfect_for_team_leads": "Team leads",
  "perfect_for_team_leads_desc": "Bring a clear report to your next review",
  "perfect_for_founders": "Founders",
  "perfect_for_founders_desc": "Show investors or clients measurable progress"
}